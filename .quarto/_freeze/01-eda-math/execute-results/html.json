{
  "hash": "b03690fa1f51840583661d6c06f2f094",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Module 1 — Data Foundations and Exploratory Data Analysis\"\nsubtitle: \"Introductory Module for Postgraduate Mathematics Students and Mathematics Faculty\"\nbibliography: reference.bib\nformat:\n  html:\n    theme: yeti\n    toc: true\n    toc-depth: 3\n    smooth-scroll: true\n    code-fold: true\nauthor: \"Siju Swamy\"\n\nexecute:\n  echo: true\n  warning: false\n  message: false\njupyter: python3\n---\n\n<div style=\"width: 100%; text-align: center;\">\n  <img src=\"M1_Dataanalysis_EDA.png\" \n       alt=\"A descriptive text for the image\" \n       style=\"width: 100%; height: auto; max-width: 1000px; display: block; margin: 0 auto;\">\n</div>\n\n\n## Introduction\n\nModern scientific research and technological innovation are fundamentally data–driven.\nAcross disciplines—engineering, healthcare, economics, environmental sciences, and artificial intelligence—data is the essential raw material that fuels knowledge creation, modelling, and decision making.\n\nThis introductory module connects mathematical theory with computational practices to prepare\nmathematicians for research and professional environments where quantitative reasoning and computational thinking play a central role.\n\n\n\n## What is Data?\n\nData refers to quantified measurements, observations, records or symbols used to describe objects, events, behaviours, or natural phenomena.\n\nIn a formal mathematical sense, data can be considered as **elements of a set**\n$$\nX = \\{x_1, x_2, \\dots, x_n\\} \\subset \\mathbb{R}^d\n$$\nwhere each $x_i$ is a $d$-dimensional vector representing measurable features.\n\nExamples:\n\n- A medical dataset: $x_i = (\\text{age}, \\text{height}, \\text{blood pressure})$\n- The Iris flower dataset: $x_i = (\\text{sepal length}, \\text{sepal width}, \\text{petal length}, \\text{petal width})$\n\n\n\n## Key Steps in Data Analysis\n\n| Step | Description |\n|-------|------------|\n| **Data Collection** | Obtaining measurements from instruments, surveys, sensors, or sources |\n| **Data Cleaning** | Handling missing, noisy, duplicated, or inconsistent values |\n| **Data Transformation** | Scaling, encoding, normalization and feature engineering |\n| **Exploratory Data Analysis (EDA)** | Statistical summarization and visual discovery of patterns |\n| **Modelling and Interpretation** | Mathematical modelling, inference, prediction, and optimization |\n| **Knowledge Communication** | Reports, dashboards, research papers, deployment |\n\n\n\n## Data Analysis vs Data Analytics\n\n| Data Analysis | Data Analytics |\n|--------------|----------------|\n| Understanding and interpreting datasets | Using data to support decisions and predictions |\n| Investigates relationships and structure | Focuses on outcomes and business/operational value |\n| More mathematical & theory oriented | More application & tool oriented |\n| Example: hypothesis testing | Example: customer churn prediction |\n\n\n\n## Role of Mathematics & Statistics in Data Analytics\n\nMathematics provides:\n\n- **Abstract structures** (sets, functions, spaces, topology)\n- **Optimization frameworks** for machine learning algorithms\n- **Linear algebra** for vectorized computation & dimensionality reduction\n- **Measure theory & probability** for uncertainty modelling\n- **Information theory** for data compression and learning\n\nStatistics provides:\n\n- Summaries, inference, estimation & hypothesis validation\n- Understanding variability and uncertainty\n- Foundations of experimental design and sampling\n\n\n\n## Perspective Shift for the Modern Mathematician (@strang2019linear)\n\nTo contribute effectively to data-centric scientific environments, a mathematician must:\n\n- Move from **closed-form solutions** to **computational approximation and simulation**\n- Accept empirical validation instead of purely symbolic proof\n- Develop algorithmic thinking and computational tool fluency\n- Translate abstract models into real-world actionable insight\n- Embrace interdisciplinary collaboration integrating computing and domain knowledge\n\n\n\n## Mathematical Formalism\n\n### **Vector Space View of Data**\n$$\nX \\subset \\mathbb{R}^d,\\qquad x_i = (x_{i1}, x_{i2}, \\dots, x_{id})\n$$\n\n### **Norm-based Measurement**\n$$\n\\|x\\|_1 = \\sum |x_i|,\\qquad \\|x\\|_2 = \\left( \\sum x_i^2 \\right)^{1/2}\n$$\n\n### **Measure Theoretic View**\n$$\n(X, \\Sigma, \\mu)\n$$\n\nwhere:\n\n- $X$ — dataset/sample space\n- $\\Sigma$ — σ-algebra of measurable subsets\n- $\\mu$ — measure assigning size/probability\n\n## Understanding Exploratory Data Analysis (EDA)\n\n### What is EDA?\n\nExploratory Data Analysis (EDA) is the process of systematically examining a dataset to\ndiscover patterns, identify anomalies, test assumptions, and validate hypotheses using\nsummary statistics and graphical representations. It is the first and most essential step\nin any analytical or machine learning workflow.\n\nIn simple terms, **EDA tells us the story hidden inside the data**.\n\n\n\n### Why is EDA Important?\n\nEDA is crucial because:\n\n- It helps understand the structure and characteristics of a dataset before formal modelling.\n- It reveals hidden relationships among variables.\n- It identifies noise, outliers, missing values, and inconsistencies.\n- It guides the selection of appropriate statistical or machine learning models.\n- It prevents incorrect assumptions that could lead to misleading conclusions.\n\nWithout EDA, modelling becomes guesswork rather than a scientifically grounded analysis.\n\n\n\n### Common Statistical Tools Used in EDA\n\n| Statistical Method | Purpose |\n|--------------------|---------|\n| Mean, Median, Mode | Central behaviour of data |\n| Variance, Standard Deviation | Spread or variability |\n| Quantiles & IQR | Range and distribution behaviour |\n| Correlation measures | Strength and direction of relationships |\n| Covariance matrices | Linear dependence structure |\n| Normality tests | Distributional assumptions |\n\n\n\n### Common Visualization Tools in EDA\n\n| Plot Type | Purpose |\n|-----------|---------|\n| Histogram | Distribution and skewness |\n| Boxplot | Outliers and spread |\n| Scatter Plot | Relationship between paired variables |\n| Pairplot (matrix plot) | All relationships in multivariate dataset |\n| Heatmap | Correlation structure |\n| Violin Plot / KDE plot | Shape of distribution |\n\nData visualization converts numeric tables into human-understandable patterns and evidence.\n\n\n\n### How EDA Helps at Different Levels\n\n| Stakeholder | Benefit |\n|-------------|---------|\n| **Common Individual** | Gains clarity about dataset behaviour without technical depth |\n| **Data Scientist / Analyst** | Learns structure, prepares features, selects models, validates assumptions |\n| **Professional Decision Maker / Policy Planner** | Makes informed strategic decisions based on evidence instead of intuition |\n\nReal-world example:\n\n- In healthcare analytics, EDA may reveal that a specific symptom correlates strongly with disease severity.\n- Decision makers can deploy targeted interventions or allocate resources precisely.\n\nThus, **EDA transforms raw data into insight, and insight into action**.\n\n## The Iris Dataset — Historical and Scientific Importance\n\nBefore conducting the exploratory analysis, it is important to introduce the dataset that\nwill be used throughout this module: the **Iris Flower Dataset**, one of the most well-known\nbenchmarks in statistics, machine learning, and pattern recognition.\n\nThe dataset was first introduced by **Sir Ronald Aylmer Fisher (1890–1962)** in his\ngroundbreaking 1936 paper titled *\"The Use of Multiple Measurements in Taxonomic Problems\"*.\nSir R. A. Fisher, widely regarded as the **Father of Modern Statistics**, pioneered foundational\nconcepts such as maximum likelihood estimation, analysis of variance (ANOVA), and statistical\nexperimental design. His Iris study demonstrated how quantitative measurements could be used\nto classify biological specimens through multivariate statistics—an idea that evolved into\nmodern machine learning classification techniques.\n\n\n### Description of the Dataset\n\nThe Iris dataset consists of **150 samples** of iris flowers collected from three species:\n\n| Species | Count |\n|---------|--------|\n| *Iris setosa* | 50 |\n| *Iris versicolor* | 50 |\n| *Iris virginica* | 50 |\n\nFor each sample, **four morphological measurements** were recorded (in centimetres):\n\n| Feature | Description |\n|----------|--------------|\n| **Sepal Length** | length of the outer part of the flower |\n| **Sepal Width** | width of the outer part |\n| **Petal Length** | length of the inner petal |\n| **Petal Width** | width of the inner petal |\n\nThus, the dataset can be represented mathematically as:\n$$\nX = \\{x_1, x_2, \\dots, x_{150}\\} \\subset \\mathbb{R}^4\n$$\nwhere each vector\n$$\nx_i = (\\text{sepal length},\\ \\text{sepal width},\\ \\text{petal length},\\ \\text{petal width})\n$$\n\nThe corresponding class label\n$$\ny_i \\in \\{\\text{setosa}, \\text{versicolor}, \\text{virginica}\\}\n$$\n\n\n\n### Why is the Iris Dataset Important?\n\n- Serves as an ideal educational dataset for demonstrating statistical and machine learning concepts.\n- Exhibits distinct geometric separation between classes, inspiring early classification algorithms.\n- Provides simple structure yet complex enough for real-world pattern recognition.\n- Forms the basis for classical methods such as **Linear Discriminant Analysis (LDA)** introduced by Fisher himself.\n\n\n### Iris Dataset and EDA\n\nThe Iris dataset is particularly suited for **Exploratory Data Analysis** because:\n\n- It contains both numeric features and categorical labels.\n- It enables visual analysis of relationships between pairs of variables.\n- It reveals distributional differences across species.\n- It supports understanding of dimensionality reduction and classification.\n\nWith this context, we now proceed to **perform a detailed EDA** of the dataset.\n\n\n\n## Exploratory Data Analysis with the Iris Dataset\n\nA glimps of the datset is shown below:\n\n::: {#a1d6eac2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load iris dataset\ndf = sns.load_dataset(\"iris\")\n\n# Display first rows\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nA summary of the dataset is shown below:\n\n::: {#d84cf1f2 .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.057333</td>\n      <td>3.758000</td>\n      <td>1.199333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.435866</td>\n      <td>1.765298</td>\n      <td>0.762238</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n>Pairwise Relationships\n\n::: {#78a197a7 .cell execution_count=3}\n``` {.python .cell-code}\nsns.pairplot(df, hue='species')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](01-eda-math_files/figure-html/cell-4-output-1.png){width=1069 height=947}\n:::\n:::\n\n\n> Feature Distributions\n\n::: {#3a02c8fe .cell execution_count=4}\n``` {.python .cell-code}\ndf.hist(figsize=(8,6), bins=10)\nplt.suptitle(\"Distribution of Features in Iris Dataset\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](01-eda-math_files/figure-html/cell-5-output-1.png){width=649 height=543}\n:::\n:::\n\n\n>Correlation Heatmap\n\n::: {#4b0ba599 .cell execution_count=5}\n``` {.python .cell-code}\nsns.heatmap(df.corr(numeric_only=True), annot=True)\nplt.title(\"Correlation Matrix\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](01-eda-math_files/figure-html/cell-6-output-1.png){width=544 height=431}\n:::\n:::\n\n\n## Reflections\n\n- How do norms relate to similarity and distance in machine learning algorithms?\n\n- How does EDA support model selection and problem formulation?\n\n- Which relationships among the Iris features appear strongest from the heatmap?\n\n## References\n\n",
    "supporting": [
      "01-eda-math_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}